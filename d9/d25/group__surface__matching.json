[
  {
    "origin": "OpenCV: Surface Matching",
    "local": ""
  },
  {
    "origin": "OpenCV",
    "local": ""
  },
  {
    "origin": "Open Source Computer Vision",
    "local": ""
  },
  {
    "origin": "Classes",
    "local": ""
  },
  {
    "origin": "Typedefs",
    "local": ""
  },
  {
    "origin": "Functions",
    "local": ""
  },
  {
    "origin": "Surface Matching",
    "local": ""
  },
  {
    "origin": "Classes",
    "local": ""
  },
  {
    "origin": "struct",
    "local": ""
  },
  {
    "origin": "struct",
    "local": ""
  },
  {
    "origin": "class",
    "local": ""
  },
  {
    "origin": "This class implements a very efficient and robust variant of the iterative closest point (",
    "local": ""
  },
  {
    "origin": ") algorithm. The task is to register a 3D model (or point cloud) against a set of noisy target data. The variants are put together by myself after certain tests. The task is to be able to match partial, noisy point clouds in cluttered scenes, quickly. You will find that my emphasis is on the performance, while retaining the accuracy. This implementation is based on Tolga Birdal's MATLAB implementation in here:",
    "local": ""
  },
  {
    "origin": "http://www.mathworks.com/matlabcentral/fileexchange/47152-icp-registration-using-efficient-variants-and-multi-resolution-scheme",
    "local": ""
  },
  {
    "origin": "The main contributions come from:",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "class",
    "local": ""
  },
  {
    "origin": "Class, allowing the storage of a pose. The data structure stores both the quaternions and the matrix forms. It supports IO functionality together with various helper methods to work with poses.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "class",
    "local": ""
  },
  {
    "origin": "When multiple poses (see",
    "local": ""
  },
  {
    "origin": ") are grouped together (contribute to the same transformation) pose clusters occur. This class is a general container for such groups of poses. It is possible to store, load and perform IO on these poses.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "class",
    "local": ""
  },
  {
    "origin": "Class, allowing the load and matching 3D models. Typical Use:",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "struct",
    "local": ""
  },
  {
    "origin": "Struct, holding a node in the hashtable.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "Typedefs",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "&lt;",
    "local": ""
  },
  {
    "origin": "&gt;",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "&lt;",
    "local": ""
  },
  {
    "origin": "&gt;",
    "local": ""
  },
  {
    "origin": "Functions",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ", double scale)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;xRange,",
    "local": ""
  },
  {
    "origin": "&amp;yRange,",
    "local": ""
  },
  {
    "origin": "&amp;zRange)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(const",
    "local": ""
  },
  {
    "origin": "&amp;PC,",
    "local": ""
  },
  {
    "origin": "&amp;PCNormals, const int NumNeighbors, const bool FlipViewpoint, const",
    "local": ""
  },
  {
    "origin": "&amp;viewpoint)",
    "local": ""
  },
  {
    "origin": "Compute the normals of an arbitrary point cloud computeNormalsPC3d uses a plane fitting approach to smoothly compute local normals. Normals are obtained through the eigenvector of the covariance matrix, corresponding to the smallest eigen value. If PCNormals is provided to be an Nx6 matrix, then no new allocation is made, instead the existing memory is overwritten.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(void *flannIndex)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "&amp;Pose)",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl)",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "(size_t size, size_t(*hashfunc)(",
    "local": ""
  },
  {
    "origin": "))",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl)",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl,",
    "local": ""
  },
  {
    "origin": "key)",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl,",
    "local": ""
  },
  {
    "origin": "key)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl,",
    "local": ""
  },
  {
    "origin": "key, void *data)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl,",
    "local": ""
  },
  {
    "origin": "key, void *data)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl)",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "(FILE *f)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl,",
    "local": ""
  },
  {
    "origin": "key)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*hashtbl, size_t size)",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "(const",
    "local": ""
  },
  {
    "origin": "*hashtbl, const size_t dataSize, FILE *f)",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "(const char *fileName, int withNormals=0)",
    "local": ""
  },
  {
    "origin": "Load a PLY file.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "static",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "value)",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ", float scale, float *Cx, float *Cy, float *Cz, float *MinVal, float *MaxVal)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(void *flannIndex,",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;indices,",
    "local": ""
  },
  {
    "origin": "&amp;distances)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(void *flannIndex,",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;indices,",
    "local": ""
  },
  {
    "origin": "&amp;distances, const int numNeighbors)",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;xrange,",
    "local": ""
  },
  {
    "origin": "&amp;yrange,",
    "local": ""
  },
  {
    "origin": "&amp;zrange, float sample_step_relative, int weightByCenter=0)",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC, int sampleStep)",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC, int sampleStep, std::vector&lt; int &gt; &amp;indices)",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ", const",
    "local": ""
  },
  {
    "origin": "&amp;Pose)",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": ", float scale, float Cx, float Cy, float Cz, float MinVal, float MaxVal)",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC, const char *fileName)",
    "local": ""
  },
  {
    "origin": "Write a point cloud to PLY file.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "void",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC, const char *fileName)",
    "local": ""
  },
  {
    "origin": "Used for debbuging pruposes, writes a point cloud to a PLY file with the tip of the normal vectors as visible red points.",
    "local": ""
  },
  {
    "origin": "More...",
    "local": ""
  },
  {
    "origin": "Detailed Description",
    "local": ""
  },
  {
    "origin": "Note about the License and Patents",
    "local": ""
  },
  {
    "origin": "The following patents have been issued for methods embodied in this software: \"Recognition and pose determination of 3D objects in 3D scenes using geometric point pair descriptors and the generalized Hough Transform\", Bertram Heinrich Drost, Markus Ulrich, EP Patent 2385483 (Nov. 21, 2012), assignee: MVTec Software GmbH, 81675 Muenchen (Germany); \"Recognition and pose determination of 3D objects in 3D scenes\", Bertram Heinrich Drost, Markus Ulrich, US Patent 8830229 (Sept. 9, 2014), assignee: MVTec Software GmbH, 81675 Muenchen (Germany). Further patents are pending. For further details, contact MVTec Software GmbH (",
    "local": ""
  },
  {
    "origin": "info@",
    "local": ""
  },
  {
    "origin": ".nosp@m.",
    "local": ""
  },
  {
    "origin": "mvte",
    "local": ""
  },
  {
    "origin": ".nosp@m.",
    "local": ""
  },
  {
    "origin": "c.com",
    "local": ""
  },
  {
    "origin": ").",
    "local": ""
  },
  {
    "origin": "Note that restrictions imposed by these patents (and possibly others) exist independently of and may be in conflict with the freedoms granted in this license, which refers to copyright of the program, not patents for any methods that it implements. Both copyright and patent law must be obeyed to legally use and redistribute this program and it is not the purpose of this license to induce you to infringe any patents or other property right claims or to contest validity of any such claims. If you redistribute or use the program, then this license merely protects you from committing copyright infringement. It does not protect you from committing patent infringement. So, before you do anything with this program, make sure that you have permission to do so not merely in terms of copyright, but also in terms of patent law.",
    "local": ""
  },
  {
    "origin": "Please note that this license is not to be understood as a guarantee either. If you use the program according to this license, but in conflict with patent law, it does not mean that the licensor will refund you for any losses that you incur if you are sued for your patent infringement.",
    "local": ""
  },
  {
    "origin": "Introduction to Surface Matching",
    "local": ""
  },
  {
    "origin": "Cameras and similar devices with the capability of sensation of 3D structure are becoming more common. Thus, using depth and intensity information for matching 3D objects (or parts) are of crucial importance for computer vision. Applications range from industrial control to guiding everyday actions for visually impaired people. The task in recognition and pose estimation in range images aims to identify and localize a queried 3D free-form object by matching it to the acquired database.",
    "local": ""
  },
  {
    "origin": "From an industrial perspective, enabling robots to automatically locate and pick up randomly placed and oriented objects from a bin is an important challenge in factory automation, replacing tedious and heavy manual labor. A system should be able to recognize and locate objects with a predefined shape and estimate the position with the precision necessary for a gripping robot to pick it up. This is where vision guided robotics takes the stage. Similar tools are also capable of guiding robots (and even people) through unstructured environments, leading to automated navigation. These properties make 3D matching from point clouds a ubiquitous necessity. Within this context, I will now describe the OpenCV implementation of a 3D object recognition and pose estimation algorithm using 3D features.",
    "local": ""
  },
  {
    "origin": "Surface Matching",
    "local": ""
  },
  {
    "origin": "Through 3D Features",
    "local": ""
  },
  {
    "origin": "The state of the algorithms in order to achieve the task 3D matching is heavily based on",
    "local": ""
  },
  {
    "origin": ", which is one of the first and main practical methods presented in this area. The approach is composed of extracting 3D feature points randomly from depth images or generic point clouds, indexing them and later in runtime querying them efficiently. Only the 3D structure is considered, and a trivial hash table is used for feature queries.",
    "local": ""
  },
  {
    "origin": "While being fully aware that utilization of the nice CAD model structure in order to achieve a smart point sampling, I will be leaving that aside now in order to respect the generalizability of the methods (Typically for such algorithms training on a CAD model is not needed, and a point cloud would be sufficient). Below is the outline of the entire algorithm:",
    "local": ""
  },
  {
    "origin": "Outline of the Algorithm",
    "local": ""
  },
  {
    "origin": "As explained, the algorithm relies on the extraction and indexing of point pair features, which are defined as follows:",
    "local": ""
  },
  {
    "origin": "\\[\\bf{{F}}(\\bf{{m1}}, \\bf{{m2}}) = (||\\bf{{d}}||_2, &lt;(\\bf{{n1}},\\bf{{d}}), &lt;(\\bf{{n2}},\\bf{{d}}), &lt;(\\bf{{n1}},\\bf{{n2}}))\\]",
    "local": ""
  },
  {
    "origin": "where \\(\\bf{{m1}}\\) and \\(\\bf{{m2}}\\) are feature two selected points on the model (or scene), \\(\\bf{{d}}\\) is the difference vector, \\(\\bf{{n1}}\\) and \\(\\bf{{n2}}\\) are the normals at \\(\\bf{{m1}}\\) and \\(\\bf{m2}\\). During the training stage, this vector is quantized, indexed. In the test stage, same features are extracted from the scene and compared to the database. With a few tricks like separation of the rotational components, the pose estimation part can also be made efficient (check the reference for more details). A Hough-like voting and clustering is employed to estimate the object pose. To cluster the poses, the raw pose hypotheses are sorted in decreasing order of the number of votes. From the highest vote, a new cluster is created. If the next pose hypothesis is close to one of the existing clusters, the hypothesis is added to the cluster and the cluster center is updated as the average of the pose hypotheses within the cluster. If the next hypothesis is not close to any of the clusters, it creates a new cluster. The proximity testing is done with fixed thresholds in translation and rotation. Distance computation and averaging for translation are performed in the 3D Euclidean space, while those for rotation are performed using quaternion representation. After clustering, the clusters are sorted in decreasing order of the total number of votes which determines confidence of the estimated poses.",
    "local": ""
  },
  {
    "origin": "This pose is further refined using \\(ICP\\) in order to obtain the final pose.",
    "local": ""
  },
  {
    "origin": "PPF presented above depends largely on robust computation of angles between 3D vectors. Even though not reported in the paper, the naive way of doing this ( \\(\\theta = cos^{-1}({\\bf{a}}\\cdot{\\bf{b}})\\) remains numerically unstable. A better way to do this is then use inverse tangents, like:",
    "local": ""
  },
  {
    "origin": "\\[&lt;(\\bf{n1},\\bf{n2})=tan^{-1}(||{\\bf{n1} \\wedge \\bf{n2}}||_2, \\bf{n1} \\cdot \\bf{n2})\\]",
    "local": ""
  },
  {
    "origin": "Rough Computation of Object Pose Given PPF",
    "local": ""
  },
  {
    "origin": "Let me summarize the following notation:",
    "local": ""
  },
  {
    "origin": "\\(p^i_m\\): \\(i^{th}\\) point of the model ( \\(p^j_m\\) accordingly)",
    "local": ""
  },
  {
    "origin": "\\(n^i_m\\): Normal of the \\(i^{th}\\) point of the model ( \\(n^j_m\\) accordingly)",
    "local": ""
  },
  {
    "origin": "\\(p^i_s\\): \\(i^{th}\\) point of the scene ( \\(p^j_s\\) accordingly)",
    "local": ""
  },
  {
    "origin": "\\(n^i_s\\): Normal of the \\(i^{th}\\) point of the scene ( \\(n^j_s\\) accordingly)",
    "local": ""
  },
  {
    "origin": "\\(T_{m\\rightarrow g}\\): The transformation required to translate \\(p^i_m\\) to the origin and rotate its normal \\(n^i_m\\) onto the \\(x\\)-axis.",
    "local": ""
  },
  {
    "origin": "\\(R_{m\\rightarrow g}\\): Rotational component of \\(T_{m\\rightarrow g}\\).",
    "local": ""
  },
  {
    "origin": "\\(t_{m\\rightarrow g}\\): Translational component of \\(T_{m\\rightarrow g}\\).",
    "local": ""
  },
  {
    "origin": "\\((p^i_m)^{'}\\): \\(i^{th}\\) point of the model transformed by \\(T_{m\\rightarrow g}\\). ( \\((p^j_m)^{'}\\) accordingly).",
    "local": ""
  },
  {
    "origin": "\\({\\bf{R_{m\\rightarrow g}}}\\): Axis angle representation of rotation \\(R_{m\\rightarrow g}\\).",
    "local": ""
  },
  {
    "origin": "\\(\\theta_{m\\rightarrow g}\\): The angular component of the axis angle representation \\({\\bf{R_{m\\rightarrow g}}}\\).",
    "local": ""
  },
  {
    "origin": "The transformation in a point pair feature is computed by first finding the transformation \\(T_{m\\rightarrow g}\\) from the first point, and applying the same transformation to the second one. Transforming each point, together with the normal, to the ground plane leaves us with an angle to find out, during a comparison with a new point pair.",
    "local": ""
  },
  {
    "origin": "We could now simply start writing",
    "local": ""
  },
  {
    "origin": "\\[(p^i_m)^{'} = T_{m\\rightarrow g} p^i_m\\]",
    "local": ""
  },
  {
    "origin": "where",
    "local": ""
  },
  {
    "origin": "\\[T_{m\\rightarrow g} = -t_{m\\rightarrow g}R_{m\\rightarrow g}\\]",
    "local": ""
  },
  {
    "origin": "Note that this is nothing but a stacked transformation. The translational component \\(t_{m\\rightarrow g}\\) reads",
    "local": ""
  },
  {
    "origin": "\\[t_{m\\rightarrow g} = -R_{m\\rightarrow g}p^i_m\\]",
    "local": ""
  },
  {
    "origin": "and the rotational being",
    "local": ""
  },
  {
    "origin": "\\[\\theta_{m\\rightarrow g} = \\cos^{-1}(n^i_m \\cdot {\\bf{x}})\\\\ {\\bf{R_{m\\rightarrow g}}} = n^i_m \\wedge {\\bf{x}}\\]",
    "local": ""
  },
  {
    "origin": "in axis angle format. Note that bold refers to the vector form. After this transformation, the feature vectors of the model are registered onto the ground plane X and the angle with respect to \\(x=0\\) is called \\(\\alpha_m\\). Similarly, for the scene, it is called \\(\\alpha_s\\).",
    "local": ""
  },
  {
    "origin": "Hough-like Voting Scheme",
    "local": ""
  },
  {
    "origin": "As shown in the outline, PPF (point pair features) are extracted from the model, quantized, stored in the hashtable and indexed, during the training stage. During the runtime however, the similar operation is perfomed on the input scene with the exception that this time a similarity lookup over the hashtable is performed, instead of an insertion. This lookup also allows us to compute a transformation to the ground plane for the scene pairs. After this point, computing the rotational component of the pose reduces to computation of the difference \\(\\alpha=\\alpha_m-\\alpha_s\\). This component carries the cue about the object pose. A Hough-like voting scheme is performed over the local model coordinate vector and \\(\\alpha\\). The highest poses achieved for every scene point lets us recover the object pose.",
    "local": ""
  },
  {
    "origin": "Source Code for PPF Matching",
    "local": ""
  },
  {
    "origin": "Pose Registration via",
    "local": ""
  },
  {
    "origin": "The matching process terminates with the attainment of the pose. However, due to the multiple matching points, erroneous hypothesis, pose averaging and etc. such pose is very open to noise and many times is far from being perfect. Although the visual results obtained in that stage are pleasing, the quantitative evaluation shows \\(~10\\) degrees variation (error), which is an acceptable level of matching. Many times, the requirement might be set well beyond this margin and it is desired to refine the computed pose.",
    "local": ""
  },
  {
    "origin": "Furthermore, in typical RGBD scenes and point clouds, 3D structure can capture only less than half of the model due to the visibility in the scene. Therefore, a robust pose refinement algorithm, which can register occluded and partially visible shapes quickly and correctly is not an unrealistic wish.",
    "local": ""
  },
  {
    "origin": "At this point, a trivial option would be to use the well known iterative closest point algorithm . However, utilization of the basic",
    "local": ""
  },
  {
    "origin": "leads to slow convergence, bad registration, outlier sensitivity and failure to register partial shapes. Thus, it is definitely not suited to the problem. For this reason, many variants have been proposed . Different variants contribute to different stages of the pose estimation process.",
    "local": ""
  },
  {
    "origin": "is composed of \\(6\\) stages and the improvements I propose for each stage is summarized below.",
    "local": ""
  },
  {
    "origin": "Sampling",
    "local": ""
  },
  {
    "origin": "To improve convergence speed and computation time, it is common to use less points than the model actually has. However, sampling the correct points to register is an issue in itself. The naive way would be to sample uniformly and hope to get a reasonable subset. More smarter ways try to identify the critical points, which are found to highly contribute to the registration process. Gelfand et. al. exploit the covariance matrix in order to constrain the eigenspace, so that a set of points which affect both translation and rotation are used. This is a clever way of subsampling, which I will optionally be using in the implementation.",
    "local": ""
  },
  {
    "origin": "Correspondence Search",
    "local": ""
  },
  {
    "origin": "As the name implies, this step is actually the assignment of the points in the data and the model in a closest point fashion. Correct assignments will lead to a correct pose, where wrong assignments strongly degrade the result. In general, KD-trees are used in the search of nearest neighbors, to increase the speed. However this is not an optimality guarantee and many times causes wrong points to be matched. Luckily the assignments are corrected over iterations.",
    "local": ""
  },
  {
    "origin": "To overcome some of the limitations, Picky",
    "local": ""
  },
  {
    "origin": "and BC-ICP (",
    "local": ""
  },
  {
    "origin": "using bi-unique correspondences) are two well-known methods. Picky",
    "local": ""
  },
  {
    "origin": "first finds the correspondences in the old-fashioned way and then among the resulting corresponding pairs, if more than one scene point \\(p_i\\) is assigned to the same model point \\(m_j\\), it selects \\(p_i\\) that corresponds to the minimum distance. BC-ICP on the other hand, allows multiple correspondences first and then resolves the assignments by establishing bi-unique correspondences. It also defines a novel no-correspondence outlier, which intrinsically eases the process of identifying outliers.",
    "local": ""
  },
  {
    "origin": "For reference, both methods are used. Because P-ICP is a bit faster, with not-so-significant performance drawback, it will be the method of choice in refinment of correspondences.",
    "local": ""
  },
  {
    "origin": "Weighting of Pairs",
    "local": ""
  },
  {
    "origin": "In my implementation, I currently do not use a weighting scheme. But the common approaches involve normal compatibility* ( \\(w_i=n^1_i\\cdot n^2_j\\)) or assigning lower weights to point pairs with greater distances ( \\(w=1-\\frac{||dist(m_i,s_i)||_2}{dist_{max}}\\)).",
    "local": ""
  },
  {
    "origin": "Rejection of Pairs",
    "local": ""
  },
  {
    "origin": "The rejections are done using a dynamic thresholding based on a robust estimate of the standard deviation. In other words, in each iteration, I find the MAD estimate of the Std. Dev. I denote this as \\(mad_i\\). I reject the pairs with distances \\(d_i&gt;\\tau mad_i\\). Here \\(\\tau\\) is the threshold of rejection and by default set to \\(3\\). The weighting is applied prior to Picky refinement, explained in the previous stage.",
    "local": ""
  },
  {
    "origin": "Metric",
    "local": ""
  },
  {
    "origin": "As described in , a linearization of point to plane as in",
    "local": ""
  },
  {
    "origin": "error metric is used. This both speeds up the registration process and improves convergence.",
    "local": ""
  },
  {
    "origin": "Minimization",
    "local": ""
  },
  {
    "origin": "Even though many non-linear optimizers (such as Levenberg Mardquardt) are proposed, due to the linearization in the previous step, pose estimation reduces to solving a linear system of equations. This is what I do exactly using",
    "local": ""
  },
  {
    "origin": "with DECOMP_SVD option.",
    "local": ""
  },
  {
    "origin": "Having described the steps above, here I summarize the layout of the",
    "local": ""
  },
  {
    "origin": "algorithm.",
    "local": ""
  },
  {
    "origin": "Efficient",
    "local": ""
  },
  {
    "origin": "Through Point Cloud Pyramids",
    "local": ""
  },
  {
    "origin": "While the up-to-now-proposed variants deal well with some outliers and bad initializations, they require significant number of iterations. Yet, multi-resolution scheme can help reducing the number of iterations by allowing the registration to start from a coarse level and propagate to the lower and finer levels. Such approach both improves the performances and enhances the runtime.",
    "local": ""
  },
  {
    "origin": "The search is done through multiple levels, in a hierarchical fashion. The registration starts with a very coarse set of samples of the model. Iteratively, the points are densified and sought. After each iteration the previously estimated pose is used as an initial pose and refined with the",
    "local": ""
  },
  {
    "origin": ".",
    "local": ""
  },
  {
    "origin": "Visual Results",
    "local": ""
  },
  {
    "origin": "Results on Synthetic Data",
    "local": ""
  },
  {
    "origin": "In all of the results, the pose is initiated by PPF and the rest is left as: \\([\\theta_x, \\theta_y, \\theta_z, t_x, t_y, t_z]=[0]\\)",
    "local": ""
  },
  {
    "origin": "Source Code for Pose Refinement Using",
    "local": ""
  },
  {
    "origin": "Results",
    "local": ""
  },
  {
    "origin": "This section is dedicated to the results of surface matching (point-pair-feature matching and a following",
    "local": ""
  },
  {
    "origin": "refinement):",
    "local": ""
  },
  {
    "origin": "Several matches of a single frog model using ppf + icp",
    "local": ""
  },
  {
    "origin": "Matches of different models for Mian dataset is presented below:",
    "local": ""
  },
  {
    "origin": "Matches of different models for Mian dataset",
    "local": ""
  },
  {
    "origin": "You might checkout the video on",
    "local": ""
  },
  {
    "origin": "youTube here",
    "local": ""
  },
  {
    "origin": ".",
    "local": ""
  },
  {
    "origin": "A Complete Sample",
    "local": ""
  },
  {
    "origin": "Parameter Tuning",
    "local": ""
  },
  {
    "origin": "Surface matching module treats its parameters relative to the model diameter (diameter of the axis parallel bounding box), whenever it can. This makes the parameters independent from the model size. This is why, both model and scene cloud were subsampled such that all points have a minimum distance of \\(RelativeSamplingStep*DimensionRange\\), where \\(DimensionRange\\) is the distance along a given dimension. All three dimensions are sampled in similar manner. For example, if \\(RelativeSamplingStep\\) is set to 0.05 and the diameter of model is 1m (1000mm), the points sampled from the object's surface will be approximately 50 mm apart. From another point of view, if the sampling RelativeSamplingStep is set to 0.05, at most \\(20x20x20 = 8000\\) model points are generated (depending on how the model fills in the volume). Consequently this results in at most 8000x8000 pairs. In practice, because the models are not uniformly distributed over a rectangular prism, much less points are to be expected. Decreasing this value, results in more model points and thus a more accurate representation. However, note that number of point pair features to be computed is now quadratically increased as the complexity is O(N\\^2). This is especially a concern for 32 bit systems, where large models can easily overshoot the available memory. Typically, values in the range of 0.025 - 0.05 seem adequate for most of the applications, where the default value is 0.03. (Note that there is a difference in this paremeter with the one presented in",
    "local": ""
  },
  {
    "origin": ". In",
    "local": ""
  },
  {
    "origin": "a uniform cuboid is used for quantization and model diameter is used for reference of sampling. In my implementation, the cuboid is a rectangular prism, and each dimension is quantized independently. I do not take reference from the diameter but along the individual dimensions.",
    "local": ""
  },
  {
    "origin": "It would very wise to remove the outliers from the model and prepare an ideal model initially. This is because, the outliers directly affect the relative computations and degrade the matching accuracy.",
    "local": ""
  },
  {
    "origin": "During runtime stage, the scene is again sampled by \\(RelativeSamplingStep\\), as described above. However this time, only a portion of the scene points are used as reference. This portion is controlled by the parameter \\(RelativeSceneSampleStep\\), where \\(SceneSampleStep = (int)(1.0/RelativeSceneSampleStep)\\). In other words, if the \\(RelativeSceneSampleStep = 1.0/5.0\\), the subsampled scene will once again be uniformly sampled to 1/5 of the number of points. Maximum value of this parameter is 1 and increasing this parameter also increases the stability, but decreases the speed. Again, because of the initial scene-independent relative sampling, fine tuning this parameter is not a big concern. This would only be an issue when the model shape occupies a volume uniformly, or when the model shape is condensed in a tiny place within the quantization volume (e.g. The octree representation would have too much empty cells).",
    "local": ""
  },
  {
    "origin": "\\(RelativeDistanceStep\\) acts as a step of discretization over the hash table. The point pair features are quantized to be mapped to the buckets of the hashtable. This discretization involves a multiplication and a casting to the integer. Adjusting RelativeDistanceStep in theory controls the collision rate. Note that, more collisions on the hashtable results in less accurate estimations. Reducing this parameter increases the affect of quantization but starts to assign non-similar point pairs to the same bins. Increasing it however, wanes the ability to group the similar pairs. Generally, because during the sampling stage, the training model points are selected uniformly with a distance controlled by RelativeSamplingStep, RelativeDistanceStep is expected to equate to this value. Yet again, values in the range of 0.025-0.05 are sensible. This time however, when the model is dense, it is not advised to decrease this value. For noisy scenes, the value can be increased to improve the robustness of the matching against noisy points.",
    "local": ""
  },
  {
    "origin": "Typedef Documentation",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "KeyType",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "Pose3DPtr",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "&lt;",
    "local": ""
  },
  {
    "origin": "&gt;",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "PoseCluster3DPtr",
    "local": ""
  },
  {
    "origin": "typedef",
    "local": ""
  },
  {
    "origin": "&lt;",
    "local": ""
  },
  {
    "origin": "&gt;",
    "local": ""
  },
  {
    "origin": "Function Documentation",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "addNoisePC()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::addNoisePC",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "double",
    "local": ""
  },
  {
    "origin": "scale",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "retval",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.addNoisePC(",
    "local": ""
  },
  {
    "origin": "pc, scale",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Adds a uniform noise in the given scale to the input point cloud",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": "Input point cloud (CV_32F family).",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "scale",
    "local": ""
  },
  {
    "origin": "Input scale of the noise. The larger the scale, the more noisy the output",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "computeBboxStd()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::computeBboxStd",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "xRange",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "yRange",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "zRange",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "computeNormalsPC3d()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::computeNormalsPC3d",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "const",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "PCNormals",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const int",
    "local": ""
  },
  {
    "origin": "NumNeighbors",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const bool",
    "local": ""
  },
  {
    "origin": "FlipViewpoint",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "viewpoint",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "retval, PCNormals",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.computeNormalsPC3d(",
    "local": ""
  },
  {
    "origin": "PC, NumNeighbors, FlipViewpoint, viewpoint[, PCNormals]",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Compute the normals of an arbitrary point cloud computeNormalsPC3d uses a plane fitting approach to smoothly compute local normals. Normals are obtained through the eigenvector of the covariance matrix, corresponding to the smallest eigen value. If PCNormals is provided to be an Nx6 matrix, then no new allocation is made, instead the existing memory is overwritten.",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": "Input point cloud to compute the normals for.",
    "local": ""
  },
  {
    "origin": "[out]",
    "local": ""
  },
  {
    "origin": "PCNormals",
    "local": ""
  },
  {
    "origin": "Output point cloud",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "NumNeighbors",
    "local": ""
  },
  {
    "origin": "Number of neighbors to take into account in a local region",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "FlipViewpoint",
    "local": ""
  },
  {
    "origin": "Should normals be flipped to a viewing direction?",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "viewpoint",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "Returns 0 on success",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "destroyFlann()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::destroyFlann",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "flannIndex",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "getRandomPose()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::getRandomPose",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "Pose",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "None",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.getRandomPose(",
    "local": ""
  },
  {
    "origin": "Pose",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Generate a random 4x4 pose matrix",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[out]",
    "local": ""
  },
  {
    "origin": "Pose",
    "local": ""
  },
  {
    "origin": "The random pose",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtable_int_clone()",
    "local": ""
  },
  {
    "origin": "* cv::ppf_match_3d::hashtable_int_clone",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableCreate()",
    "local": ""
  },
  {
    "origin": "* cv::ppf_match_3d::hashtableCreate",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "size_t",
    "local": ""
  },
  {
    "origin": "size",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "size_t(*)(",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "hashfunc",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableDestroy()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::hashtableDestroy",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableGet()",
    "local": ""
  },
  {
    "origin": "void* cv::ppf_match_3d::hashtableGet",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "key",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableGetBucketHashed()",
    "local": ""
  },
  {
    "origin": "* cv::ppf_match_3d::hashtableGetBucketHashed",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "key",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableInsert()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::hashtableInsert",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "key",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "data",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableInsertHashed()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::hashtableInsertHashed",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "key",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "data",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtablePrint()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::hashtablePrint",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableRead()",
    "local": ""
  },
  {
    "origin": "* cv::ppf_match_3d::hashtableRead",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "FILE *",
    "local": ""
  },
  {
    "origin": "f",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableRemove()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::hashtableRemove",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "key",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableResize()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::hashtableResize",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "size_t",
    "local": ""
  },
  {
    "origin": "size",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "hashtableWrite()",
    "local": ""
  },
  {
    "origin": "int cv::ppf_match_3d::hashtableWrite",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "const",
    "local": ""
  },
  {
    "origin": "*",
    "local": ""
  },
  {
    "origin": "hashtbl",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const size_t",
    "local": ""
  },
  {
    "origin": "dataSize",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "FILE *",
    "local": ""
  },
  {
    "origin": "f",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "indexPCFlann()",
    "local": ""
  },
  {
    "origin": "void* cv::ppf_match_3d::indexPCFlann",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "loadPLYSimple()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::loadPLYSimple",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "const char *",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "withNormals",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "retval",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.loadPLYSimple(",
    "local": ""
  },
  {
    "origin": "fileName[, withNormals]",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Load a PLY file.",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": "The PLY model to read",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "withNormals",
    "local": ""
  },
  {
    "origin": "Flag wheather the input PLY contains normal information, and whether it should be loaded or not",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "Returns the matrix on successful load",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "next_power_of_two()",
    "local": ""
  },
  {
    "origin": "static",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::next_power_of_two",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "value",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "inline",
    "local": ""
  },
  {
    "origin": "static",
    "local": ""
  },
  {
    "origin": "from",
    "local": ""
  },
  {
    "origin": "http://www-graphics.stanford.edu/~seander/bithacks.html",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "normalizePCCoeff()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::normalizePCCoeff",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "scale",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float *",
    "local": ""
  },
  {
    "origin": "Cx",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float *",
    "local": ""
  },
  {
    "origin": "Cy",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float *",
    "local": ""
  },
  {
    "origin": "Cz",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float *",
    "local": ""
  },
  {
    "origin": "MinVal",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float *",
    "local": ""
  },
  {
    "origin": "MaxVal",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "queryPCFlann()",
    "local": ""
  },
  {
    "origin": "[1/2]",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::queryPCFlann",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "flannIndex",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "indices",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "distances",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "queryPCFlann()",
    "local": ""
  },
  {
    "origin": "[2/2]",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::queryPCFlann",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "void *",
    "local": ""
  },
  {
    "origin": "flannIndex",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "indices",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "distances",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const int",
    "local": ""
  },
  {
    "origin": "numNeighbors",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "samplePCByQuantization()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::samplePCByQuantization",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "xrange",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "yrange",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "zrange",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "sample_step_relative",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "weightByCenter",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "retval",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.samplePCByQuantization(",
    "local": ""
  },
  {
    "origin": "pc, xrange, yrange, zrange, sample_step_relative[, weightByCenter]",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Sample a point cloud using uniform steps",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": "Input point cloud",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "xrange",
    "local": ""
  },
  {
    "origin": "X components (min and max) of the bounding box of the model",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "yrange",
    "local": ""
  },
  {
    "origin": "Y components (min and max) of the bounding box of the model",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "zrange",
    "local": ""
  },
  {
    "origin": "Z components (min and max) of the bounding box of the model",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "sample_step_relative",
    "local": ""
  },
  {
    "origin": "The point cloud is sampled such that all points have a certain minimum distance. This minimum distance is determined relatively using the parameter sample_step_relative.",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "weightByCenter",
    "local": ""
  },
  {
    "origin": "The contribution of the quantized data points can be weighted by the distance to the origin. This parameter enables/disables the use of weighting.",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "Sampled point cloud",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "samplePCUniform()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::samplePCUniform",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "sampleStep",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "samplePCUniformInd()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::samplePCUniformInd",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "int",
    "local": ""
  },
  {
    "origin": "sampleStep",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "std::vector&lt; int &gt; &amp;",
    "local": ""
  },
  {
    "origin": "indices",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "transformPCPose()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::transformPCPose",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const",
    "local": ""
  },
  {
    "origin": "&amp;",
    "local": ""
  },
  {
    "origin": "Pose",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "retval",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.transformPCPose(",
    "local": ""
  },
  {
    "origin": "pc, Pose",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Transforms the point cloud with a given a homogeneous 4x4 pose matrix (in double precision)",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": "Input point cloud (CV_32F family). Point clouds with 3 or 6 elements per row are expected. In the case where the normals are provided, they are also rotated to be compatible with the entire transformation",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "Pose",
    "local": ""
  },
  {
    "origin": "4x4 pose matrix, but linearized in row-major form.",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "Transformed point cloud",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "transPCCoeff()",
    "local": ""
  },
  {
    "origin": "cv::ppf_match_3d::transPCCoeff",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "pc",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "scale",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "Cx",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "Cy",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "Cz",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "MinVal",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "float",
    "local": ""
  },
  {
    "origin": "MaxVal",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "writePLY()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::writePLY",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const char *",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "None",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.writePLY(",
    "local": ""
  },
  {
    "origin": "PC, fileName",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Write a point cloud to PLY file.",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": "Input point cloud",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": "The PLY model file to write",
    "local": ""
  },
  {
    "origin": "◆",
    "local": ""
  },
  {
    "origin": "writePLYVisibleNormals()",
    "local": ""
  },
  {
    "origin": "void cv::ppf_match_3d::writePLYVisibleNormals",
    "local": ""
  },
  {
    "origin": "(",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": ",",
    "local": ""
  },
  {
    "origin": "const char *",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Python:",
    "local": ""
  },
  {
    "origin": "None",
    "local": ""
  },
  {
    "origin": "=",
    "local": ""
  },
  {
    "origin": "cv.ppf_match_3d.writePLYVisibleNormals(",
    "local": ""
  },
  {
    "origin": "PC, fileName",
    "local": ""
  },
  {
    "origin": ")",
    "local": ""
  },
  {
    "origin": "Used for debbuging pruposes, writes a point cloud to a PLY file with the tip of the normal vectors as visible red points.",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "PC",
    "local": ""
  },
  {
    "origin": "Input point cloud",
    "local": ""
  },
  {
    "origin": "[in]",
    "local": ""
  },
  {
    "origin": "fileName",
    "local": ""
  },
  {
    "origin": "The PLY model file to write",
    "local": ""
  },
  {
    "origin": "Generated on Fri Apr 2 2021 11:36:41 for OpenCV by",
    "local": ""
  }
]