[
  {
    "origin": "OpenCV: Meanshift and Camshift",
    "local": ""
  },
  {
    "origin": "Open Source Computer Vision",
    "local": ""
  },
  {
    "origin": "Meanshift and Camshift",
    "local": ""
  },
  {
    "origin": "Goal",
    "local": ""
  },
  {
    "origin": "We will learn about Meanshift and Camshift algorithms to find and track objects in videos.",
    "local": ""
  },
  {
    "origin": "Meanshift",
    "local": ""
  },
  {
    "origin": "The intuition behind the meanshift is simple. Consider you have a set of points. (It can be a pixel distribution like histogram backprojection). You are given a small window ( may be a circle) and you have to move that window to the area of maximum pixel density (or maximum number of points). It is illustrated in the simple image given below:",
    "local": ""
  },
  {
    "origin": "image",
    "local": ""
  },
  {
    "origin": "The initial window is shown in blue circle with the name \"C1\". Its original center is marked in blue rectangle, named \"C1_o\". But if you find the centroid of the points inside that window, you will get the point \"C1_r\" (marked in small blue circle) which is the real centroid of window. Surely they don't match. So move your window such that circle of the new window matches with previous centroid. Again find the new centroid. Most probably, it won't match. So move it again, and continue the iterations such that center of window and its centroid falls on the same location (or with a small desired error). So finally what you obtain is a window with maximum pixel distribution. It is marked with green circle, named \"C2\". As you can see in image, it has maximum number of points. The whole process is demonstrated on a static image below:",
    "local": ""
  },
  {
    "origin": "image",
    "local": ""
  },
  {
    "origin": "So we normally pass the histogram backprojected image and initial target location. When the object moves, obviously the movement is reflected in histogram backprojected image. As a result, meanshift algorithm moves our window to the new location with maximum density.",
    "local": ""
  },
  {
    "origin": "Meanshift in OpenCV.js",
    "local": ""
  },
  {
    "origin": "To use meanshift in OpenCV.js, first we need to setup the target, find its histogram so that we can backproject the target on each frame for calculation of meanshift. We also need to provide initial location of window. For histogram, only Hue is considered here. Also, to avoid false values due to low light, low light values are discarded using",
    "local": ""
  },
  {
    "origin": "function.",
    "local": ""
  },
  {
    "origin": "We use the function:",
    "local": ""
  },
  {
    "origin": "(probImage, window, criteria)",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "probImage",
    "local": ""
  },
  {
    "origin": "Back projection of the object histogram. See",
    "local": ""
  },
  {
    "origin": "for details.",
    "local": ""
  },
  {
    "origin": "window",
    "local": ""
  },
  {
    "origin": "Initial search window.",
    "local": ""
  },
  {
    "origin": "criteria",
    "local": ""
  },
  {
    "origin": "Stop criteria for the iterative search algorithm.",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "number of iterations meanShift took to converge and the new location",
    "local": ""
  },
  {
    "origin": "Try it",
    "local": ""
  },
  {
    "origin": "Camshift",
    "local": ""
  },
  {
    "origin": "It applies meanshift first. Once meanshift converges, it updates the size of the window as, \\(s = 2 \\times \\sqrt{\\frac{M_{00}}{256}}\\). It also calculates the orientation of best fitting ellipse to it. Again it applies the meanshift with new scaled search window and previous window location. The process is continued until required accuracy is met.",
    "local": ""
  },
  {
    "origin": "image",
    "local": ""
  },
  {
    "origin": "Camshift in OpenCV.js",
    "local": ""
  },
  {
    "origin": "It is almost same as meanshift, but it returns a rotated rectangle (that is our result) and box parameters (used to be passed as search window in next iteration).",
    "local": ""
  },
  {
    "origin": "We use the function:",
    "local": ""
  },
  {
    "origin": "(probImage, window, criteria)",
    "local": ""
  },
  {
    "origin": "Parameters",
    "local": ""
  },
  {
    "origin": "probImage",
    "local": ""
  },
  {
    "origin": "Back projection of the object histogram. See",
    "local": ""
  },
  {
    "origin": "for details.",
    "local": ""
  },
  {
    "origin": "window",
    "local": ""
  },
  {
    "origin": "Initial search window.",
    "local": ""
  },
  {
    "origin": "criteria",
    "local": ""
  },
  {
    "origin": "Stop criteria for the iterative search algorithm.",
    "local": ""
  },
  {
    "origin": "Returns",
    "local": ""
  },
  {
    "origin": "Rotated rectangle and the new search window",
    "local": ""
  },
  {
    "origin": "Try it",
    "local": ""
  },
  {
    "origin": "Additional Resources",
    "local": ""
  },
  {
    "origin": "French Wikipedia page on",
    "local": ""
  },
  {
    "origin": "Camshift",
    "local": ""
  },
  {
    "origin": ". (The two animations are taken from here)",
    "local": ""
  },
  {
    "origin": "Bradski, G.R., \"Real time face and object tracking as a component of a perceptual user interface,\" Applications of Computer Vision, 1998. WACV '98. Proceedings., Fourth IEEE Workshop on , vol., no., pp.214,219, 19-21 Oct 1998",
    "local": ""
  },
  {
    "origin": "Generated on Fri Apr 2 2021 11:36:37 for OpenCV by &#160;",
    "local": ""
  }
]